# -*- coding: utf-8 -*-
"""
Created on Thu Sep  9 05:09:37 2021

@author: Mayank82549
"""


from sklearn.metrics import precision_score, recall_score, accuracy_score
from sklearn.metrics import roc_auc_score, make_scorer
from sklearn.model_selection import train_test_split  # data split
import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler # data normalization
import pickle
import matplotlib.pyplot as plt # visualization
import itertools # advanced tools
from sklearn.metrics import confusion_matrix # evaluation metric
from sklearn.metrics import f1_score # evaluation metric
from xgboost import XGBClassifier
from sklearn import metrics

# Master data file in OHE format 
md1 = pd.read_pickle(r"C:\Data\Common\preprocessed_dataset_0902_v1.pickle")
#  Import Outlier csv sheet
DF_OT = pd.read_csv(r"C:\Data\MM\09032021\Outlier_File.csv")

# Define list of variables to be treated for outlier
# List_OT = []

DF_OT.set_index('Index',inplace=True)

#  Define list of variable to be dropped
drop_list2 = [
'A'
]


Var_list_SS = ['Numeric_Variable']

# Defining Target
def func_Target(x):
    if x["unbun"] == 1:
        return 1
    
    # if (x['cob']+x['mul_sur']+x['chf'])>0:
    #     return 1
    else:
        return 0
    
md1['FWA_IND'] = md1.apply(lambda x: func_Target(x), axis = 1)

# Before running below code, please make sure data is in OHE format
data_y=pd.DataFrame()
# FWA_IND
data_y = md1['FWA_IND'].copy()
drop_variable = ['A1']

data_x = md1.drop(drop_variable, axis = 1)
data_x = data_x.drop(drop_list2, axis = 1)
Temp1 = data_x.columns
X_train, X_test, y_train, y_test = train_test_split(data_x, data_y, 
                                                    test_size = 0.20, 
                                                    random_state = 0)

X_train.reset_index(inplace = True)
X_test.reset_index(inplace = True)

# Outlier Treatment

Column_List = list(DF_OT.columns)
for i in Column_List:   
#  For Train data   
    X_train[i] = np.where(X_train[i]>DF_OT.loc['max'][i],DF_OT.loc['max'][i],X_train[i])
    X_train[i] = np.where(X_train[i]<DF_OT.loc['min'][i],DF_OT.loc['min'][i],X_train[i])
#  For Test data    
    X_test[i] = np.where(X_test[i]>DF_OT.loc['max'][i],DF_OT.loc['max'][i],X_test[i])
    X_test[i] = np.where(X_test[i]<DF_OT.loc['min'][i],DF_OT.loc['min'][i],X_test[i])

# Standardization of numerical variable
scaler = StandardScaler() # Define scaler object
scaler.fit(X_train[Var_list_SS]) # train data, fit data using scaler object
pickle.dump(scaler,open(r'C:/Data/MM/09032021/StandardScaler1.pickle','wb'))
scaler=pickle.load(open('C:/Data/MM/09032021/StandardScaler1.pickle','rb'))

# For train data
Temp_Train = X_train[Var_list_SS]
X_train.drop(Var_list_SS, axis=1, inplace = True)
Temp_Train= pd.DataFrame(scaler.transform(Temp_Train), columns = Var_list_SS) # train, test
print(X_train.shape)
X_train = pd.concat([X_train,Temp_Train], axis =1)
print(X_train.shape)
# For test data
Temp_Test = X_test[Var_list_SS]
X_test.drop(Var_list_SS, axis=1, inplace = True)
Temp_Test= pd.DataFrame(scaler.transform(Temp_Test), columns = Var_list_SS) # train, test
X_test = pd.concat([X_test,Temp_Test], axis =1)

X_train_01 = X_train.drop('index', axis = 1)
X_test_01 = X_test.drop('index', axis = 1)

# Model fitting
# Default parameters
xgb = XGBClassifier(random_state=42, objective = 'binary:logistic', num_classes = 2)
xgb.fit(X_train_01, y_train)

# Used for parameter tunning
# xgb = XGBClassifier(learning_rate=0.01, n_estimators=300,
#                      max_depth=9, min_child_weight=1,
#                      gamma=0.3, subsample=0.9,
#                      colsample_bytree=0.8, objective='binary:logistic',
#                      nthread=4, scale_pos_weight=9,
#                      max_delta_step=1, reg_alpha=0,
#                      reg_lambda=1, seed=1)

# xgb.fit(X_train_01, y_train)

xgbpreds = xgb.predict(X_train_01)
xgb_matrix = confusion_matrix(y_train, xgbpreds, labels = [0, 1]) # XGBoost Train
print(xgb_matrix)
xgbpreds = xgb.predict(X_test_01)
xgb_matrix = confusion_matrix(y_test, xgbpreds, labels = [0, 1]) # XGBoost Test
print(xgb_matrix)
#Predict training set:
y_pred_train = xgb.predict(X_train_01)
y_predprob_train = xgb.predict_proba(X_train_01)[:,1]
#Predict test set:
y_pred_test = xgb.predict(X_test_01)
y_predprob_test = xgb.predict_proba(X_test_01)[:,1]

    
# Print Train model metrics:
print("\nModel Metrics- Training Data")
print('Accuracy score for train data is {}'.format(accuracy_score(y_train.values, y_pred_train)))
print("AUC Score (Train): %f" % metrics.roc_auc_score(y_train, y_predprob_train))
print("Precision Score (Train): %f" % metrics.average_precision_score(y_train, y_predprob_train))
print("Recall Score (Train): %f" % metrics.recall_score(y_train, y_pred_train))
print('F1 score of the XGBoost model is {}'.format(f1_score(y_train, y_pred_train)))

print("\nModel Metrics- Testing Data")
print('Accuracy score of the XGBoost model is {}'.format(accuracy_score(y_test, xgbpreds)))
print("Accuracy (Test) : %.4g" % metrics.accuracy_score(y_test.values, y_pred_test))
print("AUC Score (Test): %f" % metrics.roc_auc_score(y_test, y_predprob_test))
print("Precision Score (Test): %f" % metrics.average_precision_score(y_test, y_predprob_test))
print("Recall Score (Test): %f" % metrics.recall_score(y_test, y_pred_test))
print('F1 score of the XGBoost model is {}'.format(f1_score(y_test, xgbpreds)))

FI_df= pd.DataFrame(xgb.feature_importances_,
                 index=X_train_01.columns).reset_index().sort_values(by=0,ascending=False)

FI_df.to_csv("Feature_Importance.csv")

df_train = y_train.copy()
df_train['FWA_Prob']= y_predprob_train

df_test = y_test.copy()
df_test['FWA_Prob']= y_predprob_test


def ks(data=None,target=None, prob=None):
    data['target0'] = 1 - data[target]
    data['bucket'] = pd.qcut(data[prob], 10)
    grouped = data.groupby('bucket', as_index = False)
    kstable = pd.DataFrame()
    kstable['min_prob'] = grouped.min()[prob]
    kstable['max_prob'] = grouped.max()[prob]
    kstable['events']   = grouped.sum()[target]
    kstable['nonevents'] = grouped.sum()['target0']
    kstable = kstable.sort_values(by="min_prob", ascending=False).reset_index(drop = True)
    kstable['event_rate'] = (kstable.events / data[target].sum()).apply('{0:.2%}'.format)
    kstable['nonevent_rate'] = (kstable.nonevents / data['target0'].sum()).apply('{0:.2%}'.format)
    kstable['cum_eventrate']=(kstable.events / data[target].sum()).cumsum()
    kstable['cum_noneventrate']=(kstable.nonevents / data['target0'].sum()).cumsum()
    kstable['KS'] = np.round(kstable['cum_eventrate']-kstable['cum_noneventrate'], 3) * 100

    #Formating
    kstable['cum_eventrate']= kstable['cum_eventrate'].apply('{0:.2%}'.format)
    kstable['cum_noneventrate']= kstable['cum_noneventrate'].apply('{0:.2%}'.format)
    kstable.index = range(1,11)
    kstable.index.rename('Decile', inplace=True)
    pd.set_option('display.max_columns', 9)
    print(kstable)
    
    #Display KS
    from colorama import Fore
    print(Fore.RED + "KS is " + str(max(kstable['KS']))+"%"+ " at decile " + str((kstable.index[kstable['KS']==max(kstable['KS'])][0])))
    # kstable.to_csv("KSTable_"+data+".csv")
    return(kstable)

mydf = ks(data=df_train,target="FWA_IND", prob="FWA_Prob")
mydf = ks(data=df_test,target="FWA_IND", prob="FWA_Prob")






#!/usr/bin/env python
# coding: utf-8

# In[1]:


import os
os.getcwd()
os.chdir('C:/Users/Subha164950/Desktop/Subha')  
cwd = os.getcwd()
cwd


# In[2]:


import pandas as pd
import numpy as np
import xgboost as xgb
from xgboost.sklearn import XGBClassifier
from sklearn.model_selection import GridSearchCV, train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn import metrics
#from xgboost import plot_importance
from sklearn.metrics import precision_score, f1_score, recall_score, accuracy_score, average_precision_score, auc
from sklearn.metrics import roc_curve, roc_auc_score, classification_report, confusion_matrix, precision_recall_curve
from sklearn.impute import SimpleImputer
from imblearn.combine import SMOTEENN
from imblearn.under_sampling import RepeatedEditedNearestNeighbours, RandomUnderSampler, NearMiss, ClusterCentroids
from imblearn.over_sampling import SMOTE
from collections import Counter
#from pandas_profiling import ProfileReport
from matplotlib import pyplot
import matplotlib.pylab as plt
get_ipython().run_line_magic('matplotlib', 'inline')
import pickle


# In[3]:


# Read data
md1 = pd.read_pickle(r"C:\Data\Common\preprocessed_dataset_0902_v1.pickle")


# In[4]:


def func_Target(x):
#     if x["unbun"] == 1:
#         return 1
    # "UNBUN"
    if (x['cob']+x['mul_sur']+x['chf'])>0:
        return 1
    else:
        return 0
    # "NO_WA"
md1['FWA_IND'] = md1.apply(lambda x: func_Target(x), axis = 1)

# Before running below code, please make sure data is in OHE format
data_y=pd.DataFrame()
# FWA_IND
data_y = md1['FWA_IND'].copy()
drop_variable = ['ClaimNumber', 'WorksheetNumber','RemarkCode','message','cob', 'unbun', 'chf', 'mul_sur', 'FWA_IND', 
                 'wa_flag', 'IND_COB_MUL']

data_x = md1.drop(drop_variable, axis = 1)

drop_list2 = [
'A'
]

data_x = data_x.drop(drop_list2, axis = 1)


# #### Train test split with stratified option

# In[13]:


X_train, X_test, y_train, y_test = train_test_split(data_x, data_y, test_size=0.2, stratify=data_y, random_state = 1234)


# In[14]:


print(y_train.value_counts())
print(y_test.value_counts())
print(sum(data_y)/data_y.shape[0])


# ### SMOTE implementation

# In[15]:


counter = Counter(y_train)
print('Original dataset shape %s' % counter)


# In[16]:


smote = NearMiss(sampling_strategy=3/7, version=3)
X_train1, y_train1 = smote.fit_resample(X_train, y_train)
counter1           = Counter(y_train1)
print('Undersampled dataset shape %s' % counter1)


# ### XGBoost cross validation

# In[17]:


def modelfit(alg, cv_folds=5, early_stopping_rounds=50):
    
    xgb_param = alg.get_xgb_params()
    xgtrain = xgb.DMatrix(X_train1.values, label=y_train1.values)
    cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,
    metrics='aucpr', early_stopping_rounds=early_stopping_rounds, verbose_eval=False)
    alg.set_params(n_estimators=cvresult.shape[0])
    
    #Fit the algorithm on the data
    alg.fit(X_train1, y_train1, eval_metric='aucpr')
        
    #Predict training set:
    y_pred_train = alg.predict(X_train1)
    y_predprob_train = alg.predict_proba(X_train1)[:,1]
    
    #Predict test set:
    y_pred_test = alg.predict(X_test)
    y_predprob_test = alg.predict_proba(X_test)[:,1]
        
    #Print model report:
    print("\nModel Report for Training set")
    print("Accuracy (Train) : %.4g" % metrics.accuracy_score(y_train1.values, y_pred_train))
    print("AUC Score (Train): %f" % metrics.roc_auc_score(y_train1, y_predprob_train))
    print("Precision Score (Train): %f" % metrics.average_precision_score(y_train1, y_predprob_train))
    print("Recall Score (Train): %f" % metrics.recall_score(y_train1, y_pred_train))
    print("\nModel Report for Test set")
    print("Accuracy (Test) : %.4g" % metrics.accuracy_score(y_test.values, y_pred_test))
    print("AUC Score (Test): %f" % metrics.roc_auc_score(y_test, y_predprob_test))
    print("Precision Score (Test): %f" % metrics.average_precision_score(y_test, y_predprob_test))
    print("Recall Score (Test): %f" % metrics.recall_score(y_test, y_pred_test))
                    
    print(pd.Series(alg.get_booster().get_fscore()).sort_values(ascending=False)[0:30])


# #### Initial model with fixed parameters

# In[18]:


xgb1 = XGBClassifier(
 learning_rate=0.1,
 n_estimators=100,
 max_depth=5,
 min_child_weight=1,
 gamma=0,
 subsample=0.8,
 colsample_bytree=0.8,
 objective= 'binary:logistic',
 nthread=4,
 scale_pos_weight=1,
 max_delta_step=0,
 reg_alpha=0,
 reg_lambda=1,
 seed=2)

modelfit(xgb1)


# #### Get first 20 important variables

# In[19]:


X_train1 = X_train1[['A']]
X_test = X_test[['A1']]


# #### Fit the same model with reduced number of features

# In[20]:


xgb1 = XGBClassifier(
 learning_rate=0.1,
 n_estimators=100,
 max_depth=5,
 min_child_weight=1,
 gamma=0,
 subsample=0.8,
 colsample_bytree=0.8,
 objective= 'binary:logistic',
 nthread=4,
 scale_pos_weight=1,
 max_delta_step=0,
 reg_alpha=0,
 reg_lambda=1,
 seed=2)

modelfit(xgb1)


# #### Tune max_depth and min_child_weight

# In[21]:


param_test1 = {
 'max_depth':range(3,10,2),
 'min_child_weight':range(1,4,2)
}
gsearch1 = GridSearchCV(estimator = XGBClassifier(learning_rate=0.1, n_estimators=100, max_depth=5, min_child_weight=1, 
                                                  gamma=0, subsample=0.8, colsample_bytree=0.8, objective='binary:logistic', 
                                                  nthread=4, scale_pos_weight=1, seed=2), 
                        param_grid=param_test1, scoring='f1', n_jobs=-1, cv=5)
gsearch1.fit(X_train1, y_train1)
gsearch1.best_params_, gsearch1.best_score_


# #### Tune gamma

# In[22]:


param_test2 = {
 'gamma':[i/10.0 for i in range(0,5)]
}
gsearch1 = GridSearchCV(estimator = XGBClassifier(learning_rate=0.1, n_estimators=100, max_depth=9, min_child_weight=1, 
                                                  gamma=0, subsample=0.8, colsample_bytree=0.8, objective='binary:logistic', 
                                                  nthread=4, scale_pos_weight=1, seed=2), 
                        param_grid=param_test2, scoring='f1', n_jobs=-1, cv=5)
gsearch1.fit(X_train1, y_train1)
gsearch1.best_params_, gsearch1.best_score_


# #### Use tuned parameters for an updated model

# In[23]:


xgb2 = XGBClassifier(
 learning_rate=0.1,
 n_estimators=100,
 max_depth=9,
 min_child_weight=1,
 gamma=0.0,
 subsample=0.8,
 colsample_bytree=0.8,
 objective='binary:logistic',
 nthread=4,
 scale_pos_weight=1,
 max_delta_step=0,
 reg_alpha=0,
 reg_lambda=1,
 seed=2)

modelfit(xgb2)


# #### Tune subsample and colsample_bytree

# In[24]:


param_test3 = {
 'subsample':[i/10.0 for i in range(6,10)],
 'colsample_bytree':[i/10.0 for i in range(6,10)]
}
gsearch3 = GridSearchCV(estimator = XGBClassifier(learning_rate=0.1, n_estimators=100, max_depth=9, min_child_weight=1, 
                                                  gamma=0.0, subsample=0.8, colsample_bytree=0.8, objective='binary:logistic', 
                                                  nthread=4, scale_pos_weight=1, seed=2), 
                        param_grid = param_test3, scoring='f1', n_jobs=-1, cv=5)
gsearch3.fit(X_train1, y_train1)
gsearch3.best_params_, gsearch3.best_score_


# #### Rerun model wih updated parameters

# In[25]:


xgb3 = XGBClassifier(
 learning_rate=0.1,
 n_estimators=100,
 max_depth=9,
 min_child_weight=1,
 gamma=0.0,
 subsample=0.9,
 colsample_bytree=0.9,
 objective='binary:logistic',
 nthread=4,
 scale_pos_weight=9,
 max_delta_step=1,
 reg_alpha=0,
 reg_lambda=1,
 seed=2)

modelfit(xgb3)


# In[26]:


xgb4 = XGBClassifier(
 learning_rate=0.1,
 n_estimators=100,
 max_depth=9,
 min_child_weight=1,
 gamma=0.0,
 subsample=0.9,
 colsample_bytree=0.9,
 objective='binary:logistic',
 nthread=4,
 scale_pos_weight=9,
 max_delta_step=1,
 reg_alpha=0,
 reg_lambda=1,
 seed=2)

xgb4.fit(X_train1, y_train1)


# ### Model results

# In[27]:


y_pred = (xgb4.predict_proba(X_test)[:,1] >= 0.5).astype(bool)

print('F1 Accuracy : {}'.format(f1_score(y_test, y_pred)))
print('Precision Score: {}'.format(precision_score(y_test, y_pred)))
print('Recall Score: {}'.format(recall_score(y_test, y_pred)))
print(classification_report(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))


# In[ ]:




